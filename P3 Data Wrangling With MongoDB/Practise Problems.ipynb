{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Csv Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "DATADIR = \"\"\n",
    "DATAFILE = \"745090.csv\"\n",
    "\n",
    "def parse_file(datafile):\n",
    "    name = None\n",
    "    data = []\n",
    "    with open(datafile,'r') as f:\n",
    "        firstLine = f.readline()\n",
    "        name = firstLine.strip().split(',')[1]\n",
    "        secondLine = f.readline()\n",
    "        header = csv.reader(f)\n",
    "        data = (list(header))\n",
    "    # Do not change the line below\n",
    "    return (name.replace('\"',\"\"), data)\n",
    "\n",
    "\n",
    "def test():\n",
    "    datafile = os.path.join(DATADIR, DATAFILE)\n",
    "    name, data = parse_file(datafile)\n",
    "\n",
    "    assert name == \"MOUNTAIN VIEW MOFFETT FLD NAS\"\n",
    "    assert data[0][1] == \"01:00\"\n",
    "    assert data[2][0] == \"01/01/2005\"\n",
    "    assert data[2][5] == \"2\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using Xlrd Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avgcoast': 10976.933460679751,\n",
       " 'maxtime': (2013, 8, 13, 17, 0, 0),\n",
       " 'maxvalue': 18779.025510000003,\n",
       " 'mintime': (2013, 2, 3, 4, 0, 0),\n",
       " 'minvalue': 6602.113898999982}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Your task is as follows:\n",
    "- read the provided Excel file\n",
    "- find and return the min, max and average values for the COAST region\n",
    "- find and return the time value for the min and max entries\n",
    "- the time values should be returned as Python tuples\n",
    "\n",
    "Please see the test function for the expected return format\n",
    "\"\"\"\n",
    "\n",
    "import xlrd\n",
    "from zipfile import ZipFile\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "\n",
    "\n",
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    ### example on how you can get the data\n",
    "    #sheet_data = [[sheet.cell_value(r, col) for col in range(sheet.ncols)] for r in range(sheet.nrows)]\n",
    "\n",
    "    ### other useful methods:\n",
    "    # print \"\\nROWS, COLUMNS, and CELLS:\"\n",
    "    # print \"Number of rows in the sheet:\", \n",
    "    # print sheet.nrows\n",
    "    # print \"Type of data in cell (row 3, col 2):\", \n",
    "    # print sheet.cell_type(3, 2)\n",
    "    # print \"Value in cell (row 3, col 2):\", \n",
    "    # print sheet.cell_value(3, 2)\n",
    "    # print \"Get a slice of values in column 3, from rows 1-3:\"\n",
    "    # print sheet.col_values(3, start_rowx=1, end_rowx=4)\n",
    "\n",
    "    # print \"\\nDATES:\"\n",
    "    # print \"Type of data in cell (row 1, col 0):\", \n",
    "    # print sheet.cell_type(1, 0)\n",
    "    # exceltime = sheet.cell_value(1, 0)\n",
    "    # print \"Time in Excel format:\",\n",
    "    # print exceltime\n",
    "    # print \"Convert time to a Python datetime tuple, from the Excel float:\",\n",
    "    # print xlrd.xldate_as_tuple(exceltime, 0)\n",
    "    \n",
    "    \n",
    "    col_values = sheet.col_values(1,start_rowx=1,end_rowx=None)\n",
    "    \n",
    "    max_val = max(col_values)\n",
    "    min_val = min(col_values)\n",
    "    \n",
    "    max_pos = col_values.index(max_val) + 1\n",
    "    min_pos = col_values.index(min_val) + 1\n",
    "  \n",
    "    min_time = xlrd.xldate_as_tuple(sheet.cell_value(min_pos,0), 0)\n",
    "    max_time = xlrd.xldate_as_tuple(sheet.cell_value(max_pos,0), 0)\n",
    "    \n",
    "    data = {\n",
    "            'maxtime': max_time,\n",
    "            'maxvalue': max_val,\n",
    "            'mintime': min_time,\n",
    "            'minvalue': min_val,\n",
    "            'avgcoast': sum(col_values) / float(len(col_values))\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    #open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "\n",
    "    assert data['maxtime'] == (2013, 8, 13, 17, 0, 0)\n",
    "    assert round(data['maxvalue'], 10) == round(18779.02551, 10)\n",
    "\n",
    "\n",
    "test()\n",
    "\n",
    "parse_file(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_load': 18779.025510000003,\n",
       "  'station_name': 'COAST',\n",
       "  'time': (2013, 8, 13, 17, 0, 0)},\n",
       " {'max_load': 2380.1654089999956,\n",
       "  'station_name': 'EAST',\n",
       "  'time': (2013, 8, 5, 17, 0, 0)},\n",
       " {'max_load': 2281.2722140000024,\n",
       "  'station_name': 'FAR_WEST',\n",
       "  'time': (2013, 6, 26, 17, 0, 0)},\n",
       " {'max_load': 1544.7707140000005,\n",
       "  'station_name': 'NORTH',\n",
       "  'time': (2013, 8, 7, 17, 0, 0)},\n",
       " {'max_load': 24415.570226999993,\n",
       "  'station_name': 'NORTH_C',\n",
       "  'time': (2013, 8, 7, 18, 0, 0)},\n",
       " {'max_load': 5494.157645,\n",
       "  'station_name': 'SOUTHERN',\n",
       "  'time': (2013, 8, 8, 16, 0, 0)},\n",
       " {'max_load': 11433.30491600001,\n",
       "  'station_name': 'SOUTH_C',\n",
       "  'time': (2013, 8, 8, 18, 0, 0)},\n",
       " {'max_load': 1862.6137649999998,\n",
       "  'station_name': 'WEST',\n",
       "  'time': (2013, 8, 7, 17, 0, 0)}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Find the time and value of max load for each of the regions\n",
    "COAST, EAST, FAR_WEST, NORTH, NORTH_C, SOUTHERN, SOUTH_C, WEST\n",
    "and write the result out in a csv file, using pipe character | as the delimiter.\n",
    "\n",
    "An example output can be seen in the \"example.csv\" file.\n",
    "'''\n",
    "\n",
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "outfile = \"2013_Max_Loads.csv\"\n",
    "\n",
    "\n",
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "    data = []\n",
    "    # YOUR CODE HERE\n",
    "    # Remember that you can use xlrd.xldate_as_tuple(sometime, 0) to convert\n",
    "    # Excel date to Python tuple of (year, month, day, hour, minute, second)\n",
    "    \n",
    "    for i in range(1,sheet.ncols-1):\n",
    "        temp = {}\n",
    "        temp[\"station_name\"] = (sheet.cell_value(0,i))\n",
    "        \n",
    "        col_values = sheet.col_values(i,start_rowx=1,end_rowx=None)\n",
    "        max_load = max(col_values)        \n",
    "        max_pos = col_values.index(max_load) + 1\n",
    "        max_date = xlrd.xldate_as_tuple(sheet.cell_value(max_pos,0),0)\n",
    "        \n",
    "        temp[\"max_load\"] = max_load\n",
    "        temp[\"time\"] = max_date\n",
    "        data.append(temp)\n",
    "            \n",
    "    return data\n",
    "parse_file(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COAST', 2013, 8, 13, 17, 18779.025510000003]\n",
      "['EAST', 2013, 8, 5, 17, 2380.1654089999956]\n",
      "['FAR_WEST', 2013, 6, 26, 17, 2281.2722140000024]\n",
      "['NORTH', 2013, 8, 7, 17, 1544.7707140000005]\n",
      "['NORTH_C', 2013, 8, 7, 18, 24415.570226999993]\n",
      "['SOUTHERN', 2013, 8, 8, 16, 5494.157645]\n",
      "['SOUTH_C', 2013, 8, 8, 18, 11433.30491600001]\n",
      "['WEST', 2013, 8, 7, 17, 1862.6137649999998]\n"
     ]
    }
   ],
   "source": [
    "data = parse_file(datafile)\n",
    "def save_file(data, filename):\n",
    "        with open(filename,'w') as f:\n",
    "            writer = csv.writer(f, delimiter='|')\n",
    "            writer.writerow(['Station','Year','Month','Day','Hour','Max Load'])\n",
    "            \n",
    "            for row in data:\n",
    "                temp = []\n",
    "                temp.append(row['station_name'])\n",
    "                temp.extend(list(row['time'])[:-2])\n",
    "                temp.append(row['max_load'])\n",
    "                print (temp)\n",
    "                writer.writerow(temp)\n",
    "                        \n",
    "save_file(data, \"example.csv\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using Element Tree Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'email': 'omer@extremegate.com',\n",
       "  'fnm': 'Omer',\n",
       "  'insr': ['I1'],\n",
       "  'snm': 'Mei-Dan'},\n",
       " {'email': 'mcarmont@hotmail.com',\n",
       "  'fnm': 'Mike',\n",
       "  'insr': ['I2'],\n",
       "  'snm': 'Carmont'},\n",
       " {'email': 'laver17@gmail.com',\n",
       "  'fnm': 'Lior',\n",
       "  'insr': ['I3', 'I4'],\n",
       "  'snm': 'Laver'},\n",
       " {'email': 'nyska@internet-zahav.net',\n",
       "  'fnm': 'Meir',\n",
       "  'insr': ['I3'],\n",
       "  'snm': 'Nyska'},\n",
       " {'email': 'kammarh@gmail.com',\n",
       "  'fnm': 'Hagay',\n",
       "  'insr': ['I8'],\n",
       "  'snm': 'Kammar'},\n",
       " {'email': 'gideon.mann.md@gmail.com',\n",
       "  'fnm': 'Gideon',\n",
       "  'insr': ['I3', 'I5'],\n",
       "  'snm': 'Mann'},\n",
       " {'email': 'barns.nz@gmail.com',\n",
       "  'fnm': 'Barnaby',\n",
       "  'insr': ['I6'],\n",
       "  'snm': 'Clarck'},\n",
       " {'email': 'eukots@gmail.com', 'fnm': 'Eugene', 'insr': ['I7'], 'snm': 'Kots'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# Your task here is to extract data from xml on authors of an article\n",
    "# and add it to a list, one item for an author.\n",
    "# See the provided data structure for the expected format.\n",
    "# The tags for first name, surname and email should map directly\n",
    "# to the dictionary keys\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "article_file = \"exampleResearchArticle.xml\"\n",
    "\n",
    "\n",
    "def get_root(fname):\n",
    "    tree = ET.parse(fname)\n",
    "    return tree.getroot()\n",
    "\n",
    "\n",
    "def get_authors(root):\n",
    "    authors = []\n",
    "    for author in root.findall('./fm/bibl/aug/au'):\n",
    "        data = {\n",
    "                \"fnm\": None,\n",
    "                \"snm\": None,\n",
    "                \"email\": None,\n",
    "                \"insr\": []\n",
    "        }\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        data[\"fnm\"] = author.find('./fnm').text\n",
    "        data[\"snm\"] = author.find('./snm').text\n",
    "        data[\"email\"] = author.find('./email').text\n",
    "        for child in author.findall('./insr'):\n",
    "            data[\"insr\"].append(child.attrib['iid'])\n",
    "       \n",
    "        authors.append(data)\n",
    "\n",
    "    return authors\n",
    "\n",
    "\n",
    "root = get_root(article_file)\n",
    "get_authors(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Beautiful Soup Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carriers:\n",
      "All AllUS AllForeign AS G4 AA 5Y DL MQ EV F9 HA B6 OO WN NK UA VX  \n",
      "\n",
      "\n",
      "Airports:\n",
      "All AllMajors ATL BWI BOS CLT MDW ORD DAL DFW DEN DTW FLL IAH LAS LAX MIA MSP JFK LGA EWR MCO PHL PHX PDX SLC SAN SFO SEA TPA DCA IAD AllOthers UXM ABR ABI DYS ADK VZF BQN AKK KKI AKI AKO CAK 7AK KQA AUK ALM ALS ABY ALB ABQ ZXB WKK AED AEX AXN AET ABE AIA APN DQH AOO AMA ABL OQZ AOS OTS AKP EDF DQL MRI ANC AND AGN ANI ANN ANB ANV ATW ACV ARC ADM AVL HTS ASE AST AHN AKB PDK FTY ACY ATT ATK MER AUO AGS AUG AUS A28 BFL BGR BHB BRW BTI BQV A2K BTR BTL AK2 A56 BTY BPT BVD WBQ BKW BED A11 KBE BLV BLI BLM JVL BVU BJI RDM BEH BET BTT BVY OQB A50 BIC BIG BGQ BMX PWR A85 BIL BIX BGM KBC BHM BIS BYW BID BMG BMI BFB BYH BCT BOI RLU BXS BLD BYA BWG BZN BFD A23 BRD BKG PWT KTS BDR TRI BKX RBH BRO BWD BQK BCE BKC BUF IFP BUR BRL BTV MVW BNO BTM JQF UXI CDW C01 ADW CDL CGI LUR EHM CZF A61 A40 CYT MDH CLD CNM A87 CPR CDC CID JRV NRR CEM CDR CIK CMI WCR CHS CRW SPB STT CHO CYM CHA CYF WA7 CEX EGA NCN KCN VAK CYS PWK CHI DPA LOT CKX CIC CEF KCG KCL WQZ KCQ CZN CIV ZXH SSB STX CHU LUK CVG OQC A12 CHP IRC CLP CKB BKL CLE CGF CFT CLK ZXN CVN ZXI OOB COD CFA KCC A69 CDB CXF CLL KCR COS COA COU CAE CSG CBM GTR OSU CMH LCK CCR CKU CDV CBA CRP CEZ CVO CIL CGA CEC CKD CUW CPX CBE DCK ADS RBD AFW FTW DGB DAN WQW MGY DAY DAB AA8 SCC FVZ A02 DTH DTR DCU DEC XXV A36 DHB DRG DRT DLF DJN DMN DTO APA FTG DSM DSI DTL DET DTT YIP DVL DIK DLG DIO DDC FVQ DOF DHN DOV DRF A22 FQQ DUJ DBQ DLH A4K AMK DRO EAA EGE FRG HTO GA0 ESN ESD EAU EDA EDW EEK EGX KKU KEK ZXO IPL ELD BIF ELP ELV ELI EKO ELM LYU ELY EMK WDG ERI ESC EUG EVV EVM PAE EXI EIL FAI FBK A01 A6K SUU FAJ KFP FWL FAR FMN FYV XNA FAY POB FFM FIC FAQ FLG FNT FLO FNL WRI FOD FQW FHU TBN RSW FPR FSI FSM FWA FWH FYU FKL VZE FAT FRD FBS FNR GNV GVL GBH GAL GUP GAM GEK GCK GYY GCC AQY GGW AZ3 GDV AK6 FVW GLV GNU GYR FVX JGC GCN AZ1 GFK GRI GJT GRR GPZ VWZ GMT XWA KGX GBD GTF GRB GSO GLH PGV GVT GSP UAM GUM GUF GPT GKN GUC GST HGR HNS A03 HNM CMX VWD ZXJ HRL MDT HRO BDL PIB HVR HWI HHR HDN HYS HKB HLN T2X HES HIB HKY HIO ITO HHH HBH HOB HGZ HOL HYL HCR HOM HST VWX HNL MKK HNH HPB HOP HOT DWH EFD HOU HUS HSV HON HSL HUT HYA HYG WHD ICY IDA IGG ILI ZXF IND MQJ INL A57 IYK IMT IWD ISP SAW ITH KIB A59 A26 MKL JAC JAN NZC JAX NIP OAJ JMS JHW VZM JON JST JBR JLN JNU OGG KAE A37 A35 KKK AZO LUP FCA KLG KAL MUE KNB MKC MCI JHM JRF KKL A65 KYK KXA KUK VZR VZY FQD VIK MVM EAR EEN ENA KEH KTN WFB DQU EYW NQX QQB IAN GRK ILE A29 KVC AKN IGM ISO KPN IRK KKB KVL KZH 06A LMT KLW SZL TYS OBU A43 ADQ KDK A41 KNK KGK KOA KKH KOT OTZ KKA KYU LKK UUK KWT KWK LSE LAF LFT LCH XXW HII LMA TVL LNY ZXK WJF LNS LAN LAR LRD KLN HSH LSV VGT LBE LZU LAW ALZ LEB VA4 KLL LWB LWS LEW LWT LEX LBL LIH UXA LVD LNK LIT 05A LGU LNI LGB LIJ GGG LPS LPR LAM SDF LBB LYH MCN MSN A75 MMH MNZ MHT MHK MBL MLY KMO MZJ MTH MYH MWA MQT MLL MVY MCW MSS MYK MAZ MYL MXY MCK OQA MCG MCL MFR MDR MYU MLB OQL MEM XXX MCE MEI OQM MFH MTM WMK MPB 6B0 MDO MAF MDY MLS NQA MKE MHM MWL STP MIB MOT MNT MFE MSO CNY BFM MOB MOD VZG MLI MLU MRY MGM MTJ UXR MGW MMU MVL KMY MWH MOS CWA MUO NUQ MOU A13 MSL VZC MKG MYR NNK WQR AA2 ACK KEB APC WNA KPM PKA APF BNA NKI NLG ENN EWB EWN HVN ARA GON NEW MSY DQN KNW JRB TSS NYC SWF LFI PHF ONP WWT EWK IAG NME NIB IKO NIN RQI WTK OME NNL ORV OFK ORF NGU OTH LBF MA5 OHC ORT NUI NUL NUP ZNC ODW OAK OCF OFU HIF OGD OGS OKC OJC JCI OLH KOY XWS OLV OLM OMA ONN ONT OPH ORL OSH KOZ OWB UOX OXR PBK PAH PGA PPG PCE PSP PMD PAQ PFN ECP PAM PKD PKB PSC PRB DQR 1G4 DQW WQJ PDB PEC PLN PDT PNS NPA PIA KPV VYS GUS PSG PNF PNE LUF DVT AZA SCF PIR PIP UGB PQS SOP AGC PIT PSF PTU PLB PBG PTR PIH A27 KPB PHO PIZ POQ PNC PSE PTK PVY PTD PTC PTA CLM KPY KPC PGM PTH A48 ORI PML PPV TWD A17 KPR PCA WQU PTV PWM PSM PRC PQI PUC BLF PPC PVD PVC PVU PUO A39 PUB PUW OQP PGD AK5 UIN KWN RDU RMP RCA RAP RSP RDG RDV RDB A76 A04 RDR RDD RNO RNT RHI RIC RIL RIV RIW ROA RCE RST ROC RKS RFD RKD RWI ROG FAL RME RSJ ROW ROP RBY RUI RSH RSN RUT SAC SMF SAD MBS SPN SLE SLT SLN SNS SBY SMN ZXM SJT SKF SAT NKX MYF NZY SJC WSJ SIG SJU SBP SDP KSR OQS SFB SNA SBA SAF SMX STS SLK SRQ CIU SVN SAV SVA SCM BFF AVP SYB BFI LKE SDX A07 WLK SOV A31 SQV SWD SHX SKK A90 A77 SXP SYA SHR PNX OQV SHH SOW BAD SHV SHG SDY SVC SUX FSD NKT SIT SKJ SGY SKW SLQ SCJ MQY SXQ SBN WSN SVW GEG SPI SGF UST STC STG SGU STJ CPS STL SUS KSM SMK SNP PIE RMN STF SCE SHD WSB WBB WA6 VZO SVS SWO SCK SRV SSC SUN SYR TCM TIW TCT TKA TLH MCF TAL TSM TLJ TEK TAV TWE TLF TLA TEX TKE HUF A30 TEB TEH TXK DLS TVF KTB TNC TIQ TOG TKJ TKI OOK TOL TPH FOE JZE TVC TTN TTD TUS TUL TLT UTM WTL TNK TUP TCL TWF TWA TYR TYE UGI UGS UMT UMB UNK DUT UTO VDZ VLD VPS VPZ VNY VUO VEE VEL VRB VCT VCV A67 VQS VCB A70 VIS OQI CNW ACT AIN AWK WAA ALW WWA OXC KWF ALO ART ATY EAT ENV VT1 AWM PBI KWP WYS WST BAF FOK WSX WWP WMO HPN DQS SPS ICT WDB VZN IPT ISN WOW ILG ILM ILN WGO INW INT WA5 WSM OLF ORH WRL WRG YKM YAK XWC WYB YNG A63 NYL YUM KZB AK8  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "def options(soup,id):\n",
    "    option_values = []\n",
    "    carrier_list = soup.find(id=id)\n",
    "    for option in carrier_list.find_all('option'):\n",
    "        option_values.append(option['value'])\n",
    "    return option_values\n",
    "\n",
    "def print_list(label,codes):\n",
    "    print(\"\\n%s:\" %label)\n",
    "    newStr = ''\n",
    "    for c in codes:\n",
    "        newStr += (c) + \" \"\n",
    "    print (newStr,\"\\n\")\n",
    "    \n",
    "soup = BeautifulSoup(open(\"Data_Elements.html\"), \"lxml\")\n",
    "    \n",
    "codes = options(soup,'CarrierList')\n",
    "print_list(\"Carriers\",codes)\n",
    "    \n",
    "codes = options(soup,'AirportList')\n",
    "print_list(\"Airports\",codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
